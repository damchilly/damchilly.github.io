---
title: "PML_Project01"
author: "Chilly Amador"
date: "September 27, 2015"
output: html_document
---


## SYNOPSIS

###In this project, the goal is  to use data from accelerometers on the belt, forearm, arm, 
###and dumbell of 6 participants and predict the manner in which they did the exercise. 
###This is the "classe" variable in the training set. 

## PROCESS

1. Set up the working directory.
2. Load the training and testing data, and perform exploratory data analysis.
3. Preprocess the original training data, and extract the useful features using NearZeroVariance function.
4. Eliminate columns with NAs, blanks or div/0.
5. Eliminate columns with irrelevant content to assess the classe (timestamps related.)
6. Create data partition 70%-instance for training and 30%-instance for testing.
7. Create Random Forest algorithm using the “caret” package, principal components analysis and cross-validation considerations.
8. Print fitted model and check accuracy
9. Apply fitted model to 30%-instance testing dataset.
10. Print fitted model on testing dataser and check accuracy.
11. Use fitted model to generate predictions for the 20-instance dataset. 
12. Results / Predicted values: [1] B A A A A E D B A A B C B A E E A B B B
13. Calculate out of the sample error.
14. Create write up files.


### ENVIRONMENT SET UP

``` {r}
### Set up environment

options(warn=-1)
library(knitr)
library(ggplot2) 
library(dplyr)
library(AppliedPredictiveModeling) 
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
workingDirectory <- "~/Documents/COURSERAMachLearn/Project"
setwd(workingDirectory)

```

### DATA LOADING

``` {r}
OrgTraining <- read.csv("pml-training.csv", header=TRUE, sep = ",")

### Identifying attributes with near zero variance

nzv <- nearZeroVar(OrgTraining)
head(nzv)

### Loading Testing data to be use as validation set 
OrgTesting <- read.csv("pml-testing.csv", header=TRUE, sep=",")


### Creating a vector of attributes to be eliminated based on the near zero variance analysis and
### manual exploratory analysis

t <- OrgTraining[-c(1,3,4,5,6,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,
                    34,35,36,50,51,52,53,54,55,56,57,58,59,69,70,71,72,73,74,75,76,77,78,79,80,
                    81,82,83,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,103,104,105,106,107,
                    108,109,110,111,112,125,126,127,128,129,130,131,132,133,134,135,136,137,138,
                    139,141,142,143,144,145,146,147,148,149,150)]

### Eliminating in the validation dataset the same attributes eliminated in the training dataset
### plus last attribute (problem_id)

tt <- OrgTesting[-c(1,3,4,5,6,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,
                    34,35,36,50,51,52,53,54,55,56,57,58,59,69,70,71,72,73,74,75,76,77,78,79,80,
                    81,82,83,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,103,104,105,106,107,
                    108,109,110,111,112,125,126,127,128,129,130,131,132,133,134,135,136,137,138,
                    139,141,142,143,144,145,146,147,148,149,150,160)]

```


### CREATE DATA PARTITION TRAINING/TESTING SAMPLING AT 70%/30%

``` {r}
set.seed(1234)

inTrain <- createDataPartition(y=t$classe, p=0.70, list=FALSE)
training <- t[inTrain,]
testing <- t[-inTrain,]

```

### CREATE RANDOM FOREST MODEL

``` {r}

# Using Random Forest with a cross validation number = 4 (Either the number of folds or number of resampling iterations)

Sys.time()
modFit <- train(classe~., data=training, method="rf", preProcess = "pca",
                trcontrol=trainControl(method = "cv", number = 4))
Sys.time()

# Save model

save(modFit, file = "modelFit704.RData")
```

###  PRINT RANDOM FOREST MODEL

``` {r}
print(modFit, digits = 2)
```

### FINAL MODEL SUMMARY

``` {r}

print(modFit$finalModel)
```


### USED FITTED MODEL IN TESTING DATASET

``` {r}

pred <- predict(modFit,testing)
confusionMatrix(testing$classe,pred)

### PREDICT CLASSE IN 20-INSTANCE DATASET

predictions <- predict(modFit,tt)

predictions
```

### PREDICTION SUMMARY

``` {r}
summary(predictions)
```


## CALCULATE OUT OF SAMPLE ERROR

``` {r}
dim(testing)
### use predictions on Testing (length of the predictions)
length(pred)
### true accuracy of the predicted model
outOfSampleAcc <- sum(pred == testing$classe)/length(pred)
outOfSampleAcc
```

### OUT OF SAMPLE ERROR

```{r}
outOfSampleError <- (1 - outOfSampleAcc) * 100
outOfSampleError
```

### WRITE UP OF RESULTS

``` {r}
# create a character vector of the predictions and check #the length of the
# vector
predictionsChr <- c(as.character(predictions))
# length of the predicted vector
length(predictionsChr)

pml_write_files = function(x) {
  n = length(x)
  for (i in 1:n) {
    filename = paste0("problem_id_", i, ".txt")
    write.table(x[i], file = filename, quote = FALSE, row.names = FALSE, 
                col.names = FALSE)
  }
}

pml_write_files(predictionsChr)
```


